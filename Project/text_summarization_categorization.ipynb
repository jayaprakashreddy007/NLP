{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-summarization-categorization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilatvz9j7vZN",
        "_uuid": "bda23ce14c9e6cc07d459ce4f3295dcacfeb88a9",
        "execution": {
          "iopub.status.busy": "2021-11-08T00:07:11.114622Z",
          "iopub.execute_input": "2021-11-08T00:07:11.115116Z",
          "iopub.status.idle": "2021-11-08T00:07:11.121236Z",
          "shell.execute_reply.started": "2021-11-08T00:07:11.115059Z",
          "shell.execute_reply": "2021-11-08T00:07:11.120316Z"
        },
        "trusted": true
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import itertools\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "layers = keras.layers\n",
        "models = keras.models\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ai9iSmu5ucAn",
        "outputId": "58068567-7445-49a5-b1dc-7a9d63e384c6"
      },
      "source": [
        "data = pd.read_csv(\"bbc-text.csv\")\n",
        "data.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tohXyq-Gui4f",
        "outputId": "33b99a37-93a1-48c1-9e00-00dce4c77421"
      },
      "source": [
        "data['category'].value_counts()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Jra4RluuIa",
        "outputId": "862676cf-f8d5-4537-8494-4e5711368300"
      },
      "source": [
        "train_size = int(len(data) * .8)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len(data) - train_size))\n",
        "\n",
        "def train_test_split(data, train_size):\n",
        "    train = data[:train_size]\n",
        "    test = data[train_size:]\n",
        "    return train, test"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 1780\n",
            "Test size: 445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6HXfm_ciaR",
        "_uuid": "58e07108e5cb00de0e0a274b2225aa8834c43393"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwVzFlWb7vZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "_uuid": "da89fd94cb271dbe37b2deaf020a1992b15173f3",
        "execution": {
          "iopub.status.busy": "2021-11-08T00:07:12.591550Z",
          "iopub.execute_input": "2021-11-08T00:07:12.591871Z",
          "iopub.status.idle": "2021-11-08T00:07:12.600428Z",
          "shell.execute_reply.started": "2021-11-08T00:07:12.591810Z",
          "shell.execute_reply": "2021-11-08T00:07:12.599621Z"
        },
        "trusted": true,
        "outputId": "60a26452-2513-4c16-a4cd-4837b47720dc"
      },
      "source": [
        "train_cat, test_cat = train_test_split(data['category'], train_size)\n",
        "train_text, test_text = train_test_split(data['text'], train_size)\n",
        "\n",
        "max_words = 1000\n",
        "tokenize = keras.preprocessing.text.Tokenizer(num_words=max_words, \n",
        "                                              char_level=False)\n",
        "\n",
        "tokenize.fit_on_texts(train_text) # fit tokenizer to our training text data\n",
        "x_train = tokenize.texts_to_matrix(train_text)\n",
        "x_test = tokenize.texts_to_matrix(test_text)\n",
        "\n",
        "# Use sklearn utility to convert label strings to numbered index\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_cat)\n",
        "y_train = encoder.transform(train_cat)\n",
        "y_test = encoder.transform(test_cat)\n",
        "\n",
        "# Converts the labels to a one-hot representation\n",
        "num_classes = np.max(y_train) + 1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Inspect the dimenstions of our training and test data (this is helpful to debug)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (1780, 1000)\n",
            "x_test shape: (445, 1000)\n",
            "y_train shape: (1780, 5)\n",
            "y_test shape: (445, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms0L4rJidWRh",
        "_uuid": "5838e4d6eb5f04b731d73507ad74c424cbc61e89"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT6WEGF-7vZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "_uuid": "a1bbb4b632904850c9028433065f18825ab35d40",
        "execution": {
          "iopub.status.busy": "2021-11-08T00:07:12.646194Z",
          "iopub.execute_input": "2021-11-08T00:07:12.646750Z",
          "iopub.status.idle": "2021-11-08T00:07:12.739962Z",
          "shell.execute_reply.started": "2021-11-08T00:07:12.646687Z",
          "shell.execute_reply": "2021-11-08T00:07:12.739311Z"
        },
        "trusted": true,
        "outputId": "d2c12d76-148a-413f-8281-73b460939f8e"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "drop_ratio = 0.5\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, input_shape=(max_words,)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dense(num_classes))\n",
        "model.add(layers.Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)\n",
        "\n",
        "# Evaluate the accuracy of our trained model\n",
        "score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "51/51 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.8864 - val_loss: 0.1490 - val_accuracy: 0.9382\n",
            "Epoch 2/2\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9888 - val_loss: 0.1180 - val_accuracy: 0.9663\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9551\n",
            "Test loss: 0.14432784914970398\n",
            "Test accuracy: 0.9550561904907227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xNG3mVeFIT",
        "_uuid": "7f2b44f49bbcdaabad53a3fadb12a92722d65aaf"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaOlQpLteGr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "_uuid": "bccfaad25ec2a6db799d5276bcdbc7993a1179ad",
        "execution": {
          "iopub.status.busy": "2021-11-08T00:07:14.370599Z",
          "iopub.execute_input": "2021-11-08T00:07:14.370842Z",
          "iopub.status.idle": "2021-11-08T00:07:14.391869Z",
          "shell.execute_reply.started": "2021-11-08T00:07:14.370797Z",
          "shell.execute_reply": "2021-11-08T00:07:14.391126Z"
        },
        "trusted": true,
        "outputId": "74dd154a-1312-43f0-d659-a08c247b5a21"
      },
      "source": [
        "def run_experiment(batch_size, epochs, drop_ratio):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(512, input_shape=(max_words,)))\n",
        "  model.add(layers.Activation('relu'))\n",
        "  model.add(layers.Dropout(drop_ratio))\n",
        "  model.add(layers.Dense(num_classes))\n",
        "  model.add(layers.Activation('softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=0,\n",
        "                    validation_split=0.1)\n",
        "  score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=batch_size, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 4\n",
        "drop_ratio = 0.4\n",
        "run_experiment(batch_size, epochs, drop_ratio)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.1307440549135208\n",
            "Test accuracy: 0.9595505595207214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kwg1HISdvbJ",
        "_uuid": "5ebd9f0d1120bb2ac6a65b9239f84431bdc1b181"
      },
      "source": [
        "## Text Summarization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMRsHwwBsj_x",
        "outputId": "a41f0e91-8840-45b5-f4ed-d433254c5898"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "def get_sentences(article):\n",
        "  extracts=sent_tokenize(article)\n",
        "  sentences=[]\n",
        "  for extract in extracts:\n",
        "    clean_sentence=extract.replace(\"[^a-zA-Z0-9]\",\" \")   ## Removing special characters\n",
        "    obtained=word_tokenize(clean_sentence) \n",
        "    sentences.append(obtained)\n",
        "  return sentences\n",
        "\n",
        "\n",
        "from nltk.cluster.util import cosine_distance\n",
        "def get_similarity(sent_1,sent_2,stop_words):\n",
        "  \n",
        "  sent_1=[w.lower() for w in sent_1]\n",
        "  sent_2=[w.lower() for w in sent_2]\n",
        "\n",
        "  total=list(set(sent_1+sent_2)) ## Removing duplicate words in total set\n",
        "\n",
        "  vec_1= [0] * len(total)\n",
        "  vec_2= [0] * len(total)\n",
        "\n",
        "\n",
        "  ## Count Vectorization of two sentences\n",
        "  for w in sent_1:\n",
        "    if w not in stop_words:\n",
        "      vec_1[total.index(w)]+=1\n",
        "\n",
        "  for w in sent_2:\n",
        "    if w not in stop_words:\n",
        "      vec_2[total.index(w)]+=1\n",
        "\n",
        "  return 1-cosine_distance(vec_1,vec_2)\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "def build_matrix(sentences):\n",
        "  stop_words = stopwords.words('english')\n",
        "\n",
        "  sim_matrix=np.zeros((len(sentences),len(sentences)))\n",
        "  ## Adjacency matrix\n",
        "\n",
        "  for id1 in range(len(sentences)):\n",
        "    for id2 in range(len(sentences)):\n",
        "      if id1==id2:  #escaping diagonal elements\n",
        "        continue\n",
        "      else:\n",
        "        sim_matrix[id1][id2]=get_similarity(sentences[id1],sentences[id2],stop_words)\n",
        "\n",
        "  return sim_matrix\n",
        "\n",
        "def textrank(text, eps=0.000001, d=0.85):\n",
        "    score_mat = np.ones(len(text)) / len(text)\n",
        "    delta=1\n",
        "    while delta>eps:\n",
        "        score_mat_new = np.ones(len(text)) * (1 - d) / len(text) + d * text.T.dot(score_mat)\n",
        "        delta = abs(score_mat_new - score_mat).sum()\n",
        "        score_mat = score_mat_new\n",
        "\n",
        "    return score_mat_new\n",
        "\n",
        "\n",
        "def summarizer(article):\n",
        "  summarized=[]\n",
        "\n",
        "  sentence=get_sentences(article)\n",
        "\n",
        "  sim_matrix=build_matrix(sentence)\n",
        "\n",
        "  score=textrank(sim_matrix)\n",
        "\n",
        "  ranked_sentence = sorted(((score[i],s) for i,s in enumerate(sentence)), reverse=True)\n",
        "\n",
        "  req = len(ranked_sentence)//4\n",
        "\n",
        "  if req == 0: req = 1\n",
        "  \n",
        "  for i in range(req):\n",
        "      summarized.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "  return summarized\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxf-b57-0xrb"
      },
      "source": [
        "## Working on Test Data and checking results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha3j3yC_t6Hm",
        "outputId": "ff53653d-f920-4abb-c95d-3513f02ad46a"
      },
      "source": [
        "# Here's how to generate a prediction on individual examples\n",
        "text_labels = encoder.classes_ \n",
        "\n",
        "for i in range(0, 15):\n",
        "    prediction = model.predict(np.array([x_test[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction)]\n",
        "    Summary=summarizer(test_text.iloc[i])\n",
        "    print(\"Predicted label: \" + predicted_label)  \n",
        "    print(\"Summary: \\n\" + \" \".join(Summary) + \"\\n\")\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: entertainment\n",
            "Summary: \n",
            "jackson is thought to have secured the most lucrative film directing deal in history to remake king kong which is currently in production in wellington . jackson who is currently filming a remake of hollywood classic king kong said he thought that the sale of mgm studios to the sony corporation would cast further uncertainty on the project .\n",
            "\n",
            "Predicted label: tech\n",
            "Summary: \n",
            "those people live in any city and village and so we need ordinary people people with interesting faces . there are hundreds and hundreds of characters in a typical bioware game said shauna perry bioware s audio and external resources producer . the company which makes role playing games such as knights of the old republic and neverwinter nights is seeking people aged 18 to 99. the canada-based company says it was looking for a wide variety of people to use as face models for characters .\n",
            "\n",
            "Predicted label: politics\n",
            "Summary: \n",
            "mr clarke who will unveil his plans on monday said economic migration helped the uk but needed proper policing . trevor phillips chairman of the commission for racial equality called on mr clarke to denounce the suggestion britain s hospitality was being tested by immigration . the refugee council said mr howard s proposals would mean there would be no safe haven in the uk . the lib dems say they will look at his plans but tory liam fox said his party offered a clear choice on the issue .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:47: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: sport\n",
            "Summary: \n",
            "radcliffe will compete in london paula radcliffe will compete in the flora london marathon this year after deciding her schedule for 2005. the 31-year-old won the race in 2002 on her marathon debut defended her title 12 months later and will now seek a third title in the 17 april race . it doesn t get any better than this for the 25th anniversary said race director david bedford . three years ago radcliffe smashed the women s world record in two hours 18 minutes 15 seconds .\n",
            "\n",
            "Predicted label: sport\n",
            "Summary: \n",
            "her rise means australia have a player in the top 10 of the men s and women s rankings for the first time in 21 years .\n",
            "\n",
            "Predicted label: tech\n",
            "Summary: \n",
            "ultimate game award for doom 3 sci-fi shooter doom 3 has blasted away the competition at a major games ceremony the golden joystick awards . it was the only title to win twice winning ultimate game of the year and best pc game at the awards presented by little britain star matt lucas . the much-anticipated sci-fi horror doom 3 shot straight to the top of the uk games charts on its release in august .\n",
            "\n",
            "Predicted label: business\n",
            "Summary: \n",
            "algeria hit by further gas riots algeria suffered a weekend of violent protests against government plans to raise gas prices local press reports . butane gas and fuel oil are used as the main source of fuel to heat homes and cook food in algeria s remote mountain areas .\n",
            "\n",
            "Predicted label: tech\n",
            "Summary: \n",
            "fast lifts rise into record books two high-speed lifts at the world s tallest building have been officially recognised as the planet s fastest . the lifts take only 30 seconds to whisk passengers to the top of the 508m tall tfc 101 tower in taipei taiwan . the guinness book of records has declared the 17m per second speed of the two lifts the swiftest on earth .\n",
            "\n",
            "Predicted label: entertainment\n",
            "Summary: \n",
            "muslim group attacks tv drama 24 a british muslim group has criticised the new series of us drama 24 which is about to be aired on sky one claiming it portrays islam unfairly . the muslim council of britain has complained to broadcasting watchdog ofcom . it says the programme breaches editorial guidelines .\n",
            "\n",
            "Predicted label: entertainment\n",
            "Summary: \n",
            "performers have yet to be confirmed for nbc s aid relief benefit later this month . the united nations warned that the number killed in the disaster could rise sharply with aid yet to reach some remote areas .\n",
            "\n",
            "Predicted label: politics\n",
            "Summary: \n",
            "next month s budget will be mr brown s eighth since labour came to power in 1997. if a may election is called there could be as little as 18 days between the budget and the announcement of a date for the election . the full finance bill with the budget measures in it would then be returned to the commons after the election if labour secures another term in office .\n",
            "\n",
            "Predicted label: politics\n",
            "Summary: \n",
            "choose hope over fear - kennedy voters will have a clear choice between the politics of fear and the politics of hope in the next general election said charles kennedy . in his new year message the liberal democrat leader said labour and the conservatives were united in relying on fear and populist scares . he said his party was the one of hope and was ready for a 2005 poll . on the asian tsunami he said it had been very heartening to learn of the generosity being shown by britons . at home he said many people were turning to the liberal democrats as they became disheartened with the politics of the other two main parties .\n",
            "\n",
            "Predicted label: business\n",
            "Summary: \n",
            "worldcom bosses $ 54m payout ten former directors at worldcom have agreed to pay $ 54m ( £28.85m ) including $ 18m from their own pockets to settle a class action lawsuit reports say . james wareham a lawyer representing one of the directors told reuters the 10 had agreed to pay those who lost billions when the firm collapsed . the remaining $ 36m will be paid by the directors insurers . corporate governance experts said that if the directors do dip into their own pockets for the settlement it will set a new standard for the accountability of bosses when the firms they oversee face problems .\n",
            "\n",
            "Predicted label: entertainment\n",
            "Summary: \n",
            "the thriller shot straight to the number one spot after taking $ 22m ( £11.7m ) at the box office . oscar hopefuls the aviator million dollar baby and sideways all cashed in on their multiple nominations with stronger ticket sales . in hide and seek de niro plays a widower whose daughter has a creepy imaginary friend .\n",
            "\n",
            "Predicted label: sport\n",
            "Summary: \n",
            "robinson ready for difficult task england coach andy robinson faces the first major test of his tenure as he tries to get back to winning ways after the six nations defeat by wales . robinson is likely to make changes in the back row and centre after the 11-9 loss as he contemplates sunday s set-to with france at twickenham . and the midfield pairing of mathew tait and jamie noon is also under threat . olly barkley immediately allowed england to generate better field position with his kicking game after replacing debutant tait just before the hour .\n",
            "\n"
          ]
        }
      ]
    }
  ]
}